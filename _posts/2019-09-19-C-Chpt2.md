---
layout: default
title:  "Chapter 2. Solution of Linear Algebraic Equations"
date:   2019-09-19 15:07:00 +0100
categories: notes
---

This set of notes is based on Chapter 2 in Numerical Recipes in C. 

# Chapter 2. Solution of Linear Algebraic Equations

The general problem posed in this chapter is $Ax = b$, i.e.

$$
\begin{bmatrix} a_{11} & a_{12} & ... & a_{1N} \\ a_{21} & a_{22} & ... & a_{aN} \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix} 
\begin{bmatrix} x_1 \\ x_2 \\ ... \\ x_M \end{bmatrix}
= \begin{bmatrix} b_1 \\ b_2 \\ ... \\ b_M \end{bmatrix}
$$

where $A$ and $b$ are given, while $x$ and/or $A^{-1}$ need to be solved.

## 1.  Gauss-Jordan Elimination

Gauss-Jordan elimination solves the posed problem by solving for both $x$ and $A^{-1}$. As a result, it may not be computationally efficient if only $x$ is needed. It is also not efficient in its memory usage as a large right-hand-side (RHS) matrix needs to be stored and manipulated. Nevertheless, it is a straightforward and stable method that is suitable as a starting point, or baseline, for solving linear algebraic equations.

First, we quickly look at the basic operations in Gauss-Jordan elimination without pivoting. We want to find $A^{-1}$ by solving $Ay = I$, where $I$ is the identity matrix. Therefore, the full matrix to solve is:

$$
\begin{bmatrix} a_{11} & a_{12} & ... & a_{1N} \\ a_{21} & a_{22} & ... & a_{aN} \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix} 
\begin{bmatrix} x_1 & y_{11} & y_{12} & ... & y_{1N} \\ x_2 & y_{21} & y_{22} & ... & y_{2N} \\ ... \\ x_M & y_{M1} & y_{M2} & ... & y_{MN}  \end{bmatrix}
= \begin{bmatrix} b_1 & 1 & 0 & ... & 0\\ b_2 & 0 & 1 & ... & 0 \\ ... \\ b_M & 0 & 0 & ... & 1\end{bmatrix}
$$

Note that every row across the 3 matrices form one linear equation. Hence, we can replace any row with a linear combinations of itself and another row without affect the solutions, as long as the operation is done to both $A$ and $b$ (or $[b \mkern9mu I]$) in the same row. To start, we divide the first row by $a_{11}$, so that the first element in the first row of the matrix $A$ is in the form of an identity matrix (i.e. $a_{11} = 1$).

$$
\begin{bmatrix} a_{11} & a_{12} & ... & a_{1N} \\ a_{21} & a_{22} & ... & a_{aN} \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix} 
= \begin{bmatrix} 1 & \frac{a_{12}}{a_{11}} & ... & \frac{a_{1N}}{a_{11}}  \\ a_{21} & a_{22} & ... & a_{aN} \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix}
$$

Then we transform the first element in the second row to the form of an identity matrix, i.e. we want $a_{21}$ to be $0$. To do this, we subtract the second row with a linearly scaled version of the first row.

 $$
\begin{bmatrix} 1 & \frac{a_{12}}{a_{11}} & ... & \frac{a_{1N}}{a_{11}}  \\ a_{21} & a_{22} & ... & a_{aN} \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix}
= \begin{bmatrix} 1 & \frac{a_{12}}{a_{11}} & ... & \frac{a_{1N}}{a_{11}}  \\ a_{21}  - a_{21}(1) = 0 & a_{22} - a_{21}(\frac{a_{12}}{a_{11}}) & ... & a_{aN} - a_{21}(\frac{a_{1N}}{a_{11}}) \\ & ... \\ a_{M1} & a_{M2} & ... & a_{MN} \end{bmatrix}
$$

Remember that the operations must also be done to the matrix on the RHS of the equation. Therefore, the other two matrices now look like this:

 $$
\begin{bmatrix} b_1 & 1 & 0 & ... & 0\\ b_2 & 0 & 1 & ... & 0 \\ ... \\ b_M & 0 & 0 & ... & 1\end{bmatrix}
= \begin{bmatrix} \frac{b_1}{a_{11}} & \frac{1}{a_{11}} & 0 & ... & 0\\ b_2 - a_{21}(\frac{b_1}{a_{11}}) & 0 - a_{21}(\frac{1}{a_{11}}) & 0 & ... & 0 \\ ... \\ b_M & 0 & 0 & ... & 1\end{bmatrix}
$$

By also doing this subtraction to the remaining rows, all elements in the first column of $A$ would be in the form of an identity matrix (i.e. $a_{31} = a_{41} = ... = a_{M1} = 0$). Repeat the procedure of division followed by subtractions for the remaining columns, at the end of which $A$ would be transformed into an identity matrix. Now, the first column of the RHS matrix is the solution for $x$, while the rest is the square matrix $A^{-1}$.

An obvious problem to this approach is that any zero element on the diagonal would cause a divide-by-zero operation. To resolve this problem, **pivoting** is needed. The basic idea is to switch rows and/or columns to ensure that diagonal values are non-zero. In practice, the largest element is usually picked as the pivot to put on the diagonal. 

While exchanging rows is trivial, exchanging columns in $A$ means that the corresponding rows of $[x \mkern9mu y]$ need to be exchanged, so that the matrix multiplication outcome (i.e. RHS of the equation) stays the same.



