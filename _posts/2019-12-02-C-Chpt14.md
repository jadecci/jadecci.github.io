---
layout: default
title:  "Chapter 14. Statistical Description of Data"
date:   2019-12-02 15:07:00 +0100
categories: notes
---

This set of notes is based on Chapter 14 in Numerical Recipes in C. 

# Chapter 14. Statistical Description of Data

## 1. Moments (of a distribution)

Moments are statistics that describe the data's tendencies to cluster around certain values, or the shape of the distribution. The $n$-th moment of a continuous function $f(x)$ about a value $c$ is:

$$
\mu_n = \int_{-\infty}^{\infty} (x-c)^n f(x) \mathop{dx}
$$

For a probability density function (*pdf*), the zeroth moment is obviously $1$. The first moment would be the expected value (or mean), i.e. $\mathrm{E}[X]$ (we usually assume $c = 0$ for the first moment). The second (central) moment would be the variance, i.e. $\mathrm{E}[(X-\mu)^2]$ (we usually assume $c = \mathrm{E}[X]$ for second or higher moments).

For discrete distributions, the first moment (mean) is: $\mu = \frac{1}{N} \sum_{i=1}^N x_i$. The second central moment (variance) is $\mathrm{Var}(X) = \frac{1}{N-1} \sum_{i=1}^N (x_i - \mu)^2$. We use $N-1$ instead of $N$ as denominator to account for the bias in sample variance in comparison to population variance, which is by a factor of $\frac{N-1}{N}$ (see [Wikipedia](https://en.wikipedia.org/wiki/Variance#Sample_variance)). The square root of the variance is the standard deviation: $\sigma(x) = \sqrt{\mathrm{Var}(X)}$.

The third moment (skewness) is a measure of asymmetry, usually evaluated as $\mathrm{Skew}(X) = \frac{1}{N} \sum_{i=1}^N (\frac{x_i - \mu}{\sigma(x)})^3$. A positive value of skewness suggests that the distribution is right-skewed (or right-tailed), with a long tail extending in the positive $x$-axis direction. 

>Caution from the book: In real life it is good practice to believe in skewnesses only when they are several or many times as large as $\sqrt{\frac{15}{N}}$ (when $\mu$ is true mean) or $\sqrt{\frac{6}{N}}$ (when $\mu$ is sample mean).
